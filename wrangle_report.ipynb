{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reporting: wragle_report\n",
    "* Create a **300-600 word written report** called \"wrangle_report.pdf\" or \"wrangle_report.html\" that briefly describes your wrangling efforts. This is to be framed as an internal document."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WeRateDogs Twitter Archive - Data Wrangle Report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The project seeks to put in practice all what has been learnt in the Data Wrangling section of this Udacity Nanodegree program. The main goal is to wrangle the WeRateDogs twitter data to draw insights and create visualizations from the data. WeRateDogs is a twitter account that rates people's dogs with humourous comment about the dog.\n",
    "\n",
    "I have documented my wrangling efforts in this report.I was also able to draw some insights and create visualizations from the wrangled data. \n",
    " \n",
    "The tasks contained in this project are:\n",
    "\n",
    "Data Gathering\n",
    "Data Accessing\n",
    "Data Cleaning\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Gathering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data used in this project is derived from three different sources:\n",
    "\n",
    "1.Twitter archive data: download this file manually by clicking the following link: twitter_archive_enhanced.csv\n",
    "\n",
    "2. Tweet Image predictions: this file is hosted on Udacity's servers and should be downloaded programmatically using the requests library and URL provided\n",
    "\n",
    "3. Twitter API & JSON: Each tweet's retweet count and fqvorite count at minimum, and any additional data you find interesting. Using the tweet IDs in the WeRateDogs Twitter archive, query the Twitter API for each tweet's JSON data using the python's tweepy library and store each tweet's entire set of JSON data in a file called tweet_json text file. Each tweet JSON data should be written to its own line. Then read this text file line by line into a pandas DataFrame."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Assessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once gathering was complete, I went on to access the data. \n",
    "The two Data Assessments performed:\n",
    "\n",
    "1. Visual Assessment: Data was displaayed in the jupyter notebook for visual assessment but I also found it tedious scrolling up and down the notebook and found that some rows were collapsed as a result of the size of the dataset. To solve this, I made use of spreadsheet to get a wholesome view and assessment of the data.\n",
    "\n",
    "2. Programmatic Assessment: To programmatically assess the data, I made use of pandas functions and methods such as Inf0(), sample(), describe(), etc.\n",
    "\n",
    "While assessing I discovered some quality and tidiness issues with the data. These are documented as follows:\n",
    "\n",
    "#### Quality Issues:\n",
    "\n",
    "\n",
    "#### Archive_data\n",
    "Retweets are present in data and we don't want that\n",
    "\n",
    "Timestamp datatype is object and should be datatime\n",
    "\n",
    "Invalid names in archive_data less than 3 characters such as a and an\n",
    "\n",
    "Ratings appear in different columns\n",
    "\n",
    "Incorrect rating_denominator value\n",
    "\n",
    "Irrelevant columns with null values\n",
    "\n",
    "Source column appears messy\n",
    "\n",
    "#### img_predictions\n",
    "Character case inconsistency and underscores between names\n",
    "\n",
    "Missing values from img_predictions table. There are 2075 rows instead of 2356. Also some have two tweet_ids and those are probably retweets.\n",
    "\n",
    "Columns related to breed, dog prediction and confidence level should all be pl\n",
    "aced in three columns. \n",
    " \n",
    "\n",
    "#### ad_data\n",
    "id column present rather than tweet_id to enable merge.\n",
    "\n",
    "#### Tidiness issues\n",
    "\n",
    "Dog stage is in four columns and that shouldn't be so.\n",
    "\n",
    "The three tables ought to be merged into one dataset as they are related.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After identifying some data quality and tidiness issues, I fixed these issues inorder to prepare my data for use in my analysis and visualizations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data rarely comes clean. Data wrangling helps improve data usability.\n",
    "Data Wrangling is the process of cleaning, organizing and transferring raw data into the desired format for analysis and it's an important skill every data analyst should have."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
